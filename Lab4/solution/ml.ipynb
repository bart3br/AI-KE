{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PATH = os.path.join('..', 'data')\n",
    "\n",
    "DATA_FILENAME = 't-shirts.csv'\n",
    "DATA_FILE_PATH = os.path.join(DATA_DIR_PATH, DATA_FILENAME)\n",
    "\n",
    "df = pd.read_csv(DATA_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['demand']\n",
    "X = df.drop('demand', axis= 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data preprocessing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_methods = {\n",
    "    \"none\": lambda X: X,\n",
    "    \"normalization\": MinMaxScaler(),\n",
    "    \"standardization\": StandardScaler()\n",
    "}\n",
    "\n",
    "processed_data = {}\n",
    "for method, transformer in preprocessing_methods.items():\n",
    "    if method == \"none\":\n",
    "        X_train_transformed = X_train\n",
    "        X_test_transformed = X_test\n",
    "    else:\n",
    "        X_train_transformed = transformer.fit_transform(X_train)\n",
    "        X_test_transformed = transformer.transform(X_test)\n",
    "    processed_data[method] = (X_train_transformed, X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classifiers and their parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'naive_bayes': CategoricalNB(),\n",
    "    'decision_tree': DecisionTreeClassifier(),\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'naive_bayes': {\n",
    "        'fit_prior': [True, False],\n",
    "        'class_prior': [None, [0.3, 0.3, 0.4]],\n",
    "        'alpha': [0.01, 0.1, 1.0]\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 15],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test classifiers with various parameter combinations,\n",
    "return best results for each classifier with each preprocessing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for naive_bayes with none preprocessing: {'alpha': 0.01, 'class_prior': None, 'fit_prior': True}\n",
      "Best cross-validation accuracy: 0.8135\n",
      "Best parameters for decision_tree with none preprocessing: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}\n",
      "Best cross-validation accuracy: 0.9698125\n",
      "Best parameters for naive_bayes with normalization preprocessing: {'alpha': 0.01, 'class_prior': None, 'fit_prior': True}\n",
      "Best cross-validation accuracy: 0.6893125\n",
      "Best parameters for decision_tree with normalization preprocessing: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}\n",
      "Best cross-validation accuracy: 0.9698125\n",
      "Best parameters for decision_tree with standardization preprocessing: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}\n",
      "Best cross-validation accuracy: 0.96975\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "for preproc_method, (X_train_proc, X_test_proc) in processed_data.items():\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        if not (preproc_method==\"standardization\" and clf_name==\"naive_bayes\"):\n",
    "            grid_search = GridSearchCV(clf, param_grids[clf_name], cv=5, scoring='accuracy')\n",
    "            grid_search.fit(X_train_proc, Y_train)\n",
    "            \n",
    "            best_models[(preproc_method, clf_name)] = grid_search.best_estimator_\n",
    "            print(f\"Best parameters for {clf_name} with {preproc_method} preprocessing: {grid_search.best_params_}\")\n",
    "            print(f\"Best cross-validation accuracy: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare results using various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for naive_bayes with none preprocessing:\n",
      "\tAccuracy: 0.823\n",
      "\tPrecision: 0.8261190506350203\n",
      "\tRecall: 0.7190346630461844\n",
      "\tf1: 0.7469323387753914\n",
      "Metrics for decision_tree with none preprocessing:\n",
      "\tAccuracy: 0.972\n",
      "\tPrecision: 0.9659443832312778\n",
      "\tRecall: 0.9593296714758556\n",
      "\tf1: 0.9625697038081192\n",
      "Metrics for naive_bayes with normalization preprocessing:\n",
      "\tAccuracy: 0.69975\n",
      "\tPrecision: 0.7370584988817893\n",
      "\tRecall: 0.6271518950763207\n",
      "\tf1: 0.657791981957296\n",
      "Metrics for decision_tree with normalization preprocessing:\n",
      "\tAccuracy: 0.972\n",
      "\tPrecision: 0.9659443832312778\n",
      "\tRecall: 0.9593296714758556\n",
      "\tf1: 0.9625697038081192\n",
      "Metrics for decision_tree with standardization preprocessing:\n",
      "\tAccuracy: 0.972\n",
      "\tPrecision: 0.9659443832312778\n",
      "\tRecall: 0.9593296714758556\n",
      "\tf1: 0.9625697038081192\n"
     ]
    }
   ],
   "source": [
    "for (preproc_method, clf_name), model in best_models.items():\n",
    "    X_train_proc, X_test_proc = processed_data[preproc_method]\n",
    "    y_pred = model.predict(X_test_proc)\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, y_pred)\n",
    "    precision = precision_score(Y_test, y_pred, average='macro')\n",
    "    recall = recall_score(Y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(Y_test, y_pred, average='macro')\n",
    "    print(f\"Metrics for {clf_name} with {preproc_method} preprocessing:\")\n",
    "    print(f\"\\tAccuracy: {accuracy}\")\n",
    "    print(f\"\\tPrecision: {precision}\")\n",
    "    print(f\"\\tRecall: {recall}\")\n",
    "    print(f\"\\tf1: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
